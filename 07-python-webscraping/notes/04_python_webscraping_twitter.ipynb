{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11.4 Twitter Scraping\n",
    "\n",
    "In this tutorial, we will build a scraper for twitter. Twitter offer a free API to search for historical tweets. You can find the details [here](https://developer.twitter.com/en/docs/tweets/search/overview). However, the free API is limited to searches in the last 7 days. If you need less recent data, you have to pay. However, if you need a moderate amount of data, webscraping could be an alternative.\n",
    "\n",
    "Let's start from the twitter search page: https://twitter.com/search-advanced\n",
    "\n",
    "Suppose you want to search a specific Twitter account, for example `@realDonaldTrump`. The url we get is https://twitter.com/search?l=&q=from%3ArealDonaldTrump&src=typd which we can decompose into  different parts:\n",
    "- https://twitter.com/search?\n",
    "- l=\n",
    "- q=from%3ArealDonaldTrump\n",
    "- src=typd\n",
    "\n",
    "The second and last part are actually useless. The important part is the third which represents our query. We can build a more succing and still working url as https://twitter.com/search?q=from%3ArealDonaldTrump. Yes, the URL is still working and is providing exactly the same content.\n",
    "\n",
    "Suppose we wanted to extract the tweets from the page above. If we scroll in the browser, we can see more. However, how many do we get with a standard python request? Let's see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/search?q=from:realDonaldTrump\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote\n",
    "\n",
    "# Prepare url\n",
    "query = quote('realDonaldTrump')\n",
    "url_twitter = 'https://twitter.com/search?q=from:%s'\n",
    "url = url_twitter % query\n",
    "print(url)\n",
    "\n",
    "# Get page content\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html5lib')\n",
    "\n",
    "# Recover tweets\n",
    "tweets = soup.select('div[class*=\"js-stream-tweet\"]')\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weird... we do not get any result. Why? The answer relies in the headers. Let's try with \"as-real\" headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set headers\n",
    "headers = {\n",
    "        \"Host\": \"twitter.com\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64)\",\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"Accept-Language\": \"de,en-US;q=0.7,en;q=0.3\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"Referer\": \"https://twitter.com/search-advanced/\",\n",
    "        \"Connection\": \"keep-alive\"}\n",
    "\n",
    "# Get page content\n",
    "response = requests.get(url, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html5lib')\n",
    "\n",
    "# Recover tweets\n",
    "tweets = soup.select('div[class*=\"js-stream-tweet\"]')\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having good headers makes a difference!\n",
    "\n",
    "Now we have discovered how to scrape twitter by username. Clearly, we can apply the same logic and recover which are the url components needed to scrape twytter by:\n",
    "- query\n",
    "- user\n",
    "- location\n",
    "\n",
    "Moreover, we can add further constraints like:\n",
    "- location\n",
    "- timespan\n",
    "- language\n",
    "\n",
    "You just have to insert a parameter into https://twitter.com/search-advanced and see which url twitter outputs. \n",
    "\n",
    "Let's now recover the tweet content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/search?q=from:realDonaldTrump\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['GAME OVER!pic.twitter.com/yvMa6bPqfy',\n",
       " 'Incredible numbers!https://twitter.com/realdonaldtrump/status/1223099086389121026\\xa0…',\n",
       " 'THE BEST IS YET TO COME!pic.twitter.com/SOn6wRV9Zs',\n",
       " 'Thank you Iowa, I love you!https://www.pscp.tv/w/cQOMgDEzNTg4Mzh8MXZPeHdvYkxCQUx4QrT6MSzbemiKv0jhIMKEWz80dLpl7urO3cn8NWkS7psa?t=56s\\xa0…',\n",
       " 'Don Lemon, the dumbest man on television (with terrible ratings!).https://twitter.com/dailycaller/status/1221999373829144578\\xa0…',\n",
       " 'Nadler ripped final argument away from Schiff, thinks Shifty did a terrible job. They are fighting big time!https://twitter.com/julio_rosas11/status/1223090988060758021\\xa0…',\n",
       " 'Great poll in Iowa, where I just landed for a Big Rally! #KAG2020pic.twitter.com/4YCo01XYCn',\n",
       " 'Shifty Adam Schiff is a CORRUPT POLITICIAN, and probably a very sick man. He has not paid the price, yet, for what he has done to our Country!',\n",
       " 'A very good question!https://twitter.com/marklevinshow/status/1221423157749452800\\xa0…',\n",
       " 'Thank you Nick!https://twitter.com/toddstarnes/status/1221108090684264448\\xa0…',\n",
       " 'After consultation with our Great Military Leaders, designers, and others, I am pleased to present the new logo for the United States Space Force, the Sixth Branch of our Magnificent Military!pic.twitter.com/TC8pT4yHFT',\n",
       " 'All Democrats should watch this!pic.twitter.com/WFK33pR0Lv',\n",
       " 'Nothing done wrong, READ THE TRANSCRIPTS!',\n",
       " 'Why didn’t Schiff release this?https://twitter.com/marklevinshow/status/1221046836435345409\\xa0…',\n",
       " 'Cryin’ Chuck never had what it takes, and never will!https://twitter.com/kimstrassel/status/1220519043766996992\\xa0…',\n",
       " 'Thank you!https://twitter.com/jerseygirl007rn/status/1221889690464219137\\xa0…',\n",
       " '....at the judges that we have right now.',\n",
       " 'Thank you Roger, it is a big Hoax!https://twitter.com/SenatorWicker/status/1221932726674231299\\xa0…',\n",
       " 'Such a great family!https://twitter.com/cissieglynch/status/956982424554131461\\xa0…',\n",
       " 'On International Holocaust Remembrance Day, we remember the millions of precious souls who perished as a result of the horrific crimes perpetrated by the Nazi regime....https://www.whitehouse.gov/briefings-statements/presidential-message-international-holocaust-remembrance-day-2020/\\xa0…']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean tweets\n",
    "print(url)\n",
    "tweets_clean = [tweet.select('p[class*=\"tweet-text\"]')[0].text for tweet in tweets]\n",
    "tweets_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we still have one problem: scrolling. We are able to get only the first 20 tweets. How do we get more? There is a simple trick."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thGAVUV0VFVBaAgLWVi4Xv'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get min position of current search\n",
    "min_position = re.findall('data-max-position=\"(\\w+)', response.text)[0]\n",
    "min_position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use the minimum position of the current search as the maximum position of the next search, we are effectively scrolling the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/search?q=from:realDonaldTrump&max_position=thGAVUV0VFVBaAgLWVi4Xv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Incredible numbers!https://twitter.com/realdonaldtrump/status/1223099086389121026\\xa0…',\n",
       " 'Nadler ripped final argument away from Schiff, thinks Shifty did a terrible job. They are fighting big time!https://twitter.com/julio_rosas11/status/1223090988060758021\\xa0…',\n",
       " 'THE BEST IS YET TO COME!pic.twitter.com/SOn6wRV9Zs',\n",
       " 'Americans across the political spectrum are disgusted by the Washington Democrats’ Partisan Hoaxes, Witch Hunts, & Con Jobs. Registered Democrats and Independents are leaving the Democrat Party in droves, & we are welcoming these voters to the Republican Party w/ wide open arms!pic.twitter.com/UCdQXY3vPn',\n",
       " 'To keep America Safe, we have fully rebuilt the U.S. Military – it is now stronger, more powerful, and more lethal than ever before. Thanks to the courage of American Heroes, the ISIS Caliphate has been DESTROYED & its founder & leader – the animal known as al-Baghdadi – is DEAD!pic.twitter.com/9LXDf6mJKf',\n",
       " 'This November, we are going to defeat the Radical Socialist Democrats and win the Great State of Iowa in a Historic Landslide! #KAG2020pic.twitter.com/jYIbSdyGjU',\n",
       " 'Great poll in Iowa, where I just landed for a Big Rally! #KAG2020pic.twitter.com/4YCo01XYCn',\n",
       " 'Great photos from a SOUTHERN BORDER WALL Briefing with Secretary of Defense, Mark @EsperDoD!pic.twitter.com/rpGHpdoIa6',\n",
       " '“Schiff blasted for not focusing on California homeless.” @foxandfriends  His District is in terrible shape. He is a corrupt pol who only dreams of the Impeachment Hoax. In my opinion he is mentally deranged!',\n",
       " 'GAME OVER!pic.twitter.com/yvMa6bPqfy',\n",
       " 'On the Iraq War Resolution being voted on tomorrow in the House of Represenatives, we are down to 5000 soldiers, and going down, and I want everyone, Republican and Democrat, to vote their HEART!',\n",
       " 'This is what a future State of Palestine can look like, with a capital in parts of East Jerusalem.pic.twitter.com/39vw3pPrAL',\n",
       " 'Charlie, I always knew you are brilliant!https://twitter.com/charleshurt/status/611237885346467841\\xa0…',\n",
       " 'We are in very close communication with China concerning the virus. Very few cases reported in USA, but strongly on watch. We have offered China and President Xi any help that is necessary. Our experts are extraordinary!',\n",
       " 'Schiff must release the IG report, without changes or tampering, which is said to be yet further exoneration of the Impeachment Hoax. He refuses to give it. Does it link him to Whistleblower? Why is he so adamant?',\n",
       " 'I NEVER told John Bolton that the aid to Ukraine was tied to investigations into Democrats, including the Bidens. In fact, he never complained about this at the time of his very public termination. If John Bolton said this, it was only to sell a book. With that being said, the...',\n",
       " '.....Melania and I send our warmest condolences to Vanessa and the wonderful Bryant family. May God be with you all!',\n",
       " 'Nothing done wrong, READ THE TRANSCRIPTS!',\n",
       " '“Again: Read the Transcript!” Michael Goodwin, New York Post, Sunday.',\n",
       " 'A very good question!https://twitter.com/marklevinshow/status/1221423157749452800\\xa0…']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scroll down\n",
    "url2 = url + '&max_position=' + min_position\n",
    "print(url2)\n",
    "\n",
    "# Get page content\n",
    "response = requests.get(url2, headers=headers)\n",
    "soup = BeautifulSoup(response.text, 'html5lib')\n",
    "\n",
    "# Recover tweets\n",
    "tweets = soup.select('div[class*=\"js-stream-tweet\"]')\n",
    "tweets_clean = [tweet.select('p[class*=\"tweet-text\"]')[0].text for tweet in tweets]\n",
    "tweets_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can now write a small Twitter scraper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping function\n",
    "def scrape_twitter(username, since=False, until=False, n=100):\n",
    "    \n",
    "    twitter_url = 'https://twitter.com/search?q=%s&max_position='\n",
    "\n",
    "    # Add options\n",
    "    options = ' from:' + username\n",
    "    if since:\n",
    "        options += ' since:' + since\n",
    "    if until:\n",
    "        options += ' until:' + until\n",
    "    url = twitter_url % quote(options)\n",
    "\n",
    "    # Scrape data\n",
    "    active = True\n",
    "    max_position = ''\n",
    "    df_tweets = pd.DataFrame()\n",
    "\n",
    "    print(url+max_position)\n",
    "\n",
    "    while active:\n",
    "        df, max_position = get_data(url+max_position)\n",
    "        df_tweets = df_tweets.append(df, sort=False)\n",
    "        if len(df_tweets) >= n or not max_position:\n",
    "            active = False\n",
    "            \n",
    "    return df_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data module\n",
    "def get_data(url):\n",
    "\n",
    "    # Set headers\n",
    "    headers = {\n",
    "        \"Host\": \"twitter.com\",\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64)\",\n",
    "        \"Accept\": \"application/json, text/javascript, */*; q=0.01\",\n",
    "        \"Accept-Language\": \"de,en-US;q=0.7,en;q=0.3\",\n",
    "        \"X-Requested-With\": \"XMLHttpRequest\",\n",
    "        \"Referer\": url,\n",
    "        \"Connection\": \"keep-alive\"}\n",
    "\n",
    "    # Get data\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # Clean data\n",
    "    df = clean_data(response)\n",
    "    min_position = re.findall('data-max-position=\"(\\w+)', response.text)[0]\n",
    "    print(\".\", end='')\n",
    "\n",
    "    return df, min_position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def clean_data(response):\n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html5lib')\n",
    "    tweets = soup.select('div[class*=\"js-stream-tweet\"]')\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    for tweet in tweets:\n",
    "        temp_df = pd.DataFrame(index=[0])\n",
    "        temp_df['user_name'] = tweet.attrs['data-name']\n",
    "        date = re.findall('data-time=\"(\\\\d*)\"', str(tweet))[0]\n",
    "        temp_df['date'] = datetime.datetime.fromtimestamp(int(date))\n",
    "        temp_df['text'] = tweet.select('p[class*=\"tweet-text\"]')[0].text\n",
    "        stat = re.findall('data\\-tweet\\-stat\\-count=\"(\\\\d*)\"', str(tweet))\n",
    "        temp_df['comments'] = int(stat[0])\n",
    "        temp_df['retweets'] = int(stat[1])\n",
    "        temp_df['likes'] = int(stat[2])\n",
    "        temp_df['mentions'] = \", \".join(re.findall('(@\\\\w*)', tweet.text))\n",
    "        temp_df['hashtags'] = \", \".join(re.findall('(#\\\\w*)', tweet.text))\n",
    "        df = df.append(temp_df, sort=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://twitter.com/search?q=%20from%3ArealDonaldTrump%20since%3A2020-01-01&max_position=\n",
      "....."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>comments</th>\n",
       "      <th>retweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>mentions</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-31 15:33:25</td>\n",
       "      <td>Incredible numbers!https://twitter.com/realdon...</td>\n",
       "      <td>2468</td>\n",
       "      <td>7513</td>\n",
       "      <td>29688</td>\n",
       "      <td>@realDonaldTrump, @realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-31 15:25:15</td>\n",
       "      <td>Nadler ripped final argument away from Schiff,...</td>\n",
       "      <td>4455</td>\n",
       "      <td>8406</td>\n",
       "      <td>29144</td>\n",
       "      <td>@realDonaldTrump, @Julio_Rosas11</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-31 05:22:00</td>\n",
       "      <td>THE BEST IS YET TO COME!pic.twitter.com/SOn6wR...</td>\n",
       "      <td>9240</td>\n",
       "      <td>21057</td>\n",
       "      <td>78618</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-31 04:16:35</td>\n",
       "      <td>Americans across the political spectrum are di...</td>\n",
       "      <td>9338</td>\n",
       "      <td>16767</td>\n",
       "      <td>60148</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-31 04:04:06</td>\n",
       "      <td>To keep America Safe, we have fully rebuilt th...</td>\n",
       "      <td>3646</td>\n",
       "      <td>11960</td>\n",
       "      <td>47817</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-27 06:18:33</td>\n",
       "      <td>I NEVER told John Bolton that the aid to Ukrai...</td>\n",
       "      <td>44248</td>\n",
       "      <td>29265</td>\n",
       "      <td>123514</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-27 00:54:34</td>\n",
       "      <td>.....Melania and I send our warmest condolence...</td>\n",
       "      <td>6357</td>\n",
       "      <td>33875</td>\n",
       "      <td>261024</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-26 21:39:07</td>\n",
       "      <td>Nothing done wrong, READ THE TRANSCRIPTS!</td>\n",
       "      <td>19483</td>\n",
       "      <td>18156</td>\n",
       "      <td>110234</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-26 16:06:45</td>\n",
       "      <td>“Again: Read the Transcript!” Michael Goodwin,...</td>\n",
       "      <td>7953</td>\n",
       "      <td>12146</td>\n",
       "      <td>56791</td>\n",
       "      <td>@realDonaldTrump</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald J. Trump</td>\n",
       "      <td>2020-01-26 15:16:25</td>\n",
       "      <td>A very good question!https://twitter.com/markl...</td>\n",
       "      <td>9028</td>\n",
       "      <td>19445</td>\n",
       "      <td>72823</td>\n",
       "      <td>@realDonaldTrump, @marklevinshow</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_name                date  \\\n",
       "0   Donald J. Trump 2020-01-31 15:33:25   \n",
       "0   Donald J. Trump 2020-01-31 15:25:15   \n",
       "0   Donald J. Trump 2020-01-31 05:22:00   \n",
       "0   Donald J. Trump 2020-01-31 04:16:35   \n",
       "0   Donald J. Trump 2020-01-31 04:04:06   \n",
       "..              ...                 ...   \n",
       "0   Donald J. Trump 2020-01-27 06:18:33   \n",
       "0   Donald J. Trump 2020-01-27 00:54:34   \n",
       "0   Donald J. Trump 2020-01-26 21:39:07   \n",
       "0   Donald J. Trump 2020-01-26 16:06:45   \n",
       "0   Donald J. Trump 2020-01-26 15:16:25   \n",
       "\n",
       "                                                 text  comments  retweets  \\\n",
       "0   Incredible numbers!https://twitter.com/realdon...      2468      7513   \n",
       "0   Nadler ripped final argument away from Schiff,...      4455      8406   \n",
       "0   THE BEST IS YET TO COME!pic.twitter.com/SOn6wR...      9240     21057   \n",
       "0   Americans across the political spectrum are di...      9338     16767   \n",
       "0   To keep America Safe, we have fully rebuilt th...      3646     11960   \n",
       "..                                                ...       ...       ...   \n",
       "0   I NEVER told John Bolton that the aid to Ukrai...     44248     29265   \n",
       "0   .....Melania and I send our warmest condolence...      6357     33875   \n",
       "0           Nothing done wrong, READ THE TRANSCRIPTS!     19483     18156   \n",
       "0   “Again: Read the Transcript!” Michael Goodwin,...      7953     12146   \n",
       "0   A very good question!https://twitter.com/markl...      9028     19445   \n",
       "\n",
       "     likes                            mentions hashtags  \n",
       "0    29688  @realDonaldTrump, @realDonaldTrump           \n",
       "0    29144    @realDonaldTrump, @Julio_Rosas11           \n",
       "0    78618                    @realDonaldTrump           \n",
       "0    60148                    @realDonaldTrump           \n",
       "0    47817                    @realDonaldTrump           \n",
       "..     ...                                 ...      ...  \n",
       "0   123514                    @realDonaldTrump           \n",
       "0   261024                    @realDonaldTrump           \n",
       "0   110234                    @realDonaldTrump           \n",
       "0    56791                    @realDonaldTrump           \n",
       "0    72823    @realDonaldTrump, @marklevinshow           \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape first 100 tweets of Donald Trump in 2020\n",
    "username = 'realDonaldTrump'\n",
    "since = '2020-01-01'\n",
    "df = scrape_twitter(username=username, since=since)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We made it! Now we have a nice short script to scrape twitter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "- Mitchell, R. (2018). *Web scraping with Python: Collecting more data from the modern web*. O'Reilly Media, Inc.\n",
    "- Vanden Broucke, S., & Baesens, B. (2018). *Practical Web scraping for data science*. New York, NY: Apress."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
